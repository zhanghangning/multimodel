import os
import shutil
from pathlib import Path

import torch
import open_clip
from open_clip import create_model_and_transforms


def cache_clip_model(model_name, pretrained_tag, bin_file_path, commit_id=None):
    """
    å°† CLIP æ¨¡å‹æƒé‡æ–‡ä»¶ç¼“å­˜åˆ° huggingface æ ¼å¼çš„æœ¬åœ°è·¯å¾„ä¸­ã€‚
    ç„¶åæ‰‹åŠ¨åŠ è½½æ¨¡å‹æƒé‡ä»¥é¿å…ç½‘ç»œè¯·æ±‚ã€‚
    """

    # æ„å»ºæ¨¡å‹æ ‡è¯†åï¼ˆæ›¿æ¢éæ³•å­—ç¬¦ï¼‰
    model_identifier = f"timm/{model_name.replace('-', '_')}_clip_224.{pretrained_tag}"

    # é»˜è®¤ commit idï¼ˆå¯ä»¥æ˜¯ä»»æ„å­—ç¬¦ä¸²ï¼‰
    if not commit_id:
        commit_id = "e3f870d679c8970b358d6e6a4c408d2e"  # å›ºå®šä¸€ä¸ª ID

    # ç¼“å­˜æ ¹ç›®å½•
    cache_root = Path.home() / ".cache" / "huggingface" / "hub"

    # æ„å»ºå®Œæ•´è·¯å¾„
    model_cache_dir = (
        cache_root /
        f"models--{model_identifier.replace('/', '--')}" /
        "snapshots" /
        commit_id
    )

    # åˆ›å»ºç›®å½•
    model_cache_dir.mkdir(parents=True, exist_ok=True)

    # ç›®æ ‡è·¯å¾„
    target_path = model_cache_dir / "open_clip_pytorch_model.bin"

    # å¤åˆ¶æ–‡ä»¶
    if not target_path.exists():
        shutil.copy(bin_file_path, target_path)
        print(f"âœ… æ¨¡å‹æ–‡ä»¶å·²ç¼“å­˜è‡³: {target_path}")
    else:
        print(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶: {target_path}")

    # æ‰‹åŠ¨ä»æœ¬åœ°åŠ è½½æ¨¡å‹
    print("ğŸ”„ å¼€å§‹ä»æœ¬åœ°åŠ è½½æ¨¡å‹...")

    model, _, processor = create_model_and_transforms(
        model_name,
        pretrained=None,  # å…³é”®ï¼šç¦ç”¨é¢„è®­ç»ƒä¸‹è½½
        precision='fp32',
        device="cpu"
    )

    # åŠ è½½æœ¬åœ°æƒé‡
    checkpoint_path = str(target_path)
    state_dict = torch.load(checkpoint_path, map_location="cpu")
    model.load_state_dict(state_dict)

    print("âœ… æˆåŠŸä»æœ¬åœ°åŠ è½½ CLIP æ¨¡å‹ï¼")
    return model, processor


if __name__ == "__main__":
    # ======================
    # ğŸ”§ ç”¨æˆ·é…ç½®åŒº
    # ======================

    MODEL_NAME = "ViT-B-32"
    PRETRAINED_TAG = "laion400m_e32"
    BIN_FILE_PATH = r"F:\programs\open_clip_pytorch_model.bin"  # æ›¿æ¢ä¸ºä½ è‡ªå·±çš„è·¯å¾„
    COMMIT_ID = None

    # ======================
    # ğŸš€ æ‰§è¡Œç¼“å­˜ + åŠ è½½æ“ä½œ
    # ======================
    model, processor = cache_clip_model(MODEL_NAME, PRETRAINED_TAG, BIN_FILE_PATH, COMMIT_ID)